{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db5ea960",
   "metadata": {},
   "source": [
    "# Embeddings MVP Example\n",
    "\n",
    "This notebook demonstrates a simple embedding workflow:\n",
    "1. Convert text to vector embeddings\n",
    "2. Compare similarity between texts\n",
    "3. Find the most similar text from a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce086339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishwajayawickrama/Desktop/Codes/Tensor-Chat/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Loading embedding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qs/gz5mqzl57l7__qhg_fn_lc1w0000gn/T/ipykernel_9200/1143619747.py:12: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embedding model loaded!\n"
     ]
    }
   ],
   "source": [
    "# MVP Embedding Example - Setup\n",
    "import numpy as np\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")   \n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize embeddings model\n",
    "print(\"ğŸ”„ Loading embedding model...\")\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "print(\"âœ… Embedding model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00ac65e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š Knowledge Base:\n",
      "1. Python is a programming language used for web development and data science.\n",
      "2. Machine learning is a subset of artificial intelligence that learns from data.\n",
      "3. Neural networks are inspired by the human brain and used in deep learning.\n",
      "4. JavaScript is primarily used for web development and frontend applications.\n",
      "5. Data visualization helps people understand complex datasets through charts and graphs.\n",
      "6. Natural language processing enables computers to understand human language.\n",
      "7. Databases store and organize data for applications and websites.\n",
      "\n",
      "ğŸ“Š Total documents: 7\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a knowledge base of texts\n",
    "knowledge_base = [\n",
    "    \"Python is a programming language used for web development and data science.\",\n",
    "    \"Machine learning is a subset of artificial intelligence that learns from data.\",\n",
    "    \"Neural networks are inspired by the human brain and used in deep learning.\",\n",
    "    \"JavaScript is primarily used for web development and frontend applications.\",\n",
    "    \"Data visualization helps people understand complex datasets through charts and graphs.\",\n",
    "    \"Natural language processing enables computers to understand human language.\",\n",
    "    \"Databases store and organize data for applications and websites.\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ“š Knowledge Base:\")\n",
    "for i, text in enumerate(knowledge_base, 1):\n",
    "    print(f\"{i}. {text}\")\n",
    "    \n",
    "print(f\"\\nğŸ“Š Total documents: {len(knowledge_base)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ca3cc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Converting texts to embeddings...\n",
      "âœ… Processed document 1/7\n",
      "âœ… Processed document 2/7\n",
      "âœ… Processed document 3/7\n",
      "âœ… Processed document 4/7\n",
      "âœ… Processed document 5/7\n",
      "âœ… Processed document 6/7\n",
      "âœ… Processed document 5/7\n",
      "âœ… Processed document 6/7\n",
      "âœ… Processed document 7/7\n",
      "\n",
      "ğŸ“ Embeddings shape: (7, 384)\n",
      "ğŸ“ Each embedding has 384 dimensions\n",
      "âœ… Processed document 7/7\n",
      "\n",
      "ğŸ“ Embeddings shape: (7, 384)\n",
      "ğŸ“ Each embedding has 384 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Convert all texts to embeddings\n",
    "print(\"ğŸ”„ Converting texts to embeddings...\")\n",
    "\n",
    "# Convert each text to embeddings\n",
    "knowledge_embeddings = []\n",
    "for i, text in enumerate(knowledge_base):\n",
    "    embedding = embeddings.embed_query(text)\n",
    "    knowledge_embeddings.append(embedding)\n",
    "    print(f\"âœ… Processed document {i+1}/{len(knowledge_base)}\")\n",
    "\n",
    "# Convert to numpy array for easier manipulation\n",
    "knowledge_embeddings = np.array(knowledge_embeddings)\n",
    "print(f\"\\nğŸ“ Embeddings shape: {knowledge_embeddings.shape}\")\n",
    "print(f\"ğŸ“ Each embedding has {knowledge_embeddings.shape[1]} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b419c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Searching for: 'What is AI and machine learning?'\n",
      "1. (Similarity: 0.809) Machine learning is a subset of artificial intelligence that learns from data.\n",
      "2. (Similarity: 0.490) Neural networks are inspired by the human brain and used in deep learning.\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Searching for: 'How to build websites?'\n",
      "1. (Similarity: 0.355) Databases store and organize data for applications and websites.\n",
      "2. (Similarity: 0.295) JavaScript is primarily used for web development and frontend applications.\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Searching for: 'Understanding data better'\n",
      "1. (Similarity: 0.512) Data visualization helps people understand complex datasets through charts and graphs.\n",
      "2. (Similarity: 0.403) Databases store and organize data for applications and websites.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Search function - Find most similar text\n",
    "def find_most_similar(query_text, top_k=3):\n",
    "    \"\"\"Find the most similar texts to a query\"\"\"\n",
    "    print(f\"ğŸ” Searching for: '{query_text}'\")\n",
    "    \n",
    "    # Convert query to embedding\n",
    "    query_embedding = embeddings.embed_query(query_text)\n",
    "    query_embedding = np.array([query_embedding])  # Reshape for cosine_similarity\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = cosine_similarity(query_embedding, knowledge_embeddings)[0]\n",
    "\n",
    "    \n",
    "    # # Get top-k most similar\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    \n",
    "    # print(f\"\\nğŸ“‹ Top {top_k} most similar texts:\")\n",
    "    results = []\n",
    "    for i, idx in enumerate(top_indices, 1):\n",
    "        similarity_score = similarities[idx]\n",
    "        similar_text = knowledge_base[idx]\n",
    "        results.append((similarity_score, similar_text))\n",
    "        print(f\"{i}. (Similarity: {similarity_score:.3f}) {similar_text}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test the search function\n",
    "test_queries = [\n",
    "    \"What is AI and machine learning?\",\n",
    "    \"How to build websites?\",\n",
    "    \"Understanding data better\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    find_most_similar(query, top_k=2)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9663f981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ Uncomment the last line above to try interactive search!\n",
      "ğŸ’¡ Or run: interactive_search()\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Interactive search - Try your own queries!\n",
    "def interactive_search():\n",
    "    \"\"\"Interactive search function\"\"\"\n",
    "    print(\"ğŸ¯ Interactive Search Mode\")\n",
    "    print(\"Type your question and see the most relevant results!\")\n",
    "    print(\"Type 'quit' to exit\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_query = input(\"ğŸ’­ Your question: \").strip()\n",
    "        \n",
    "        if user_query.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"ğŸ‘‹ Goodbye!\")\n",
    "            break\n",
    "            \n",
    "        if not user_query:\n",
    "            print(\"Please enter a question!\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            results = find_most_similar(user_query, top_k=3)\n",
    "            print()\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {e}\")\n",
    "            print()\n",
    "\n",
    "# Uncomment the line below to start interactive mode\n",
    "# interactive_search()\n",
    "\n",
    "print(\"ğŸ’¡ Uncomment the last line above to try interactive search!\")\n",
    "print(\"ğŸ’¡ Or run: interactive_search()\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
